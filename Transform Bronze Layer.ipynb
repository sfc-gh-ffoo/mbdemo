{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "47fs6zoogotfsduqmpkf",
   "authorId": "8660255417248",
   "authorName": "DRAMKUMAR",
   "authorEmail": "danaraj.ramkumar@snowflake.com",
   "sessionId": "400746e9-7eb5-4b9f-aa8c-474475902e0f",
   "lastEditTime": 1764917948314
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "6c48c31b-b30b-41ef-8054-3bc88d379cc3",
   "metadata": {
    "language": "python",
    "name": "Initialize_Spark",
    "collapsed": true,
    "codeCollapsed": true
   },
   "outputs": [],
   "source": "from snowflake import snowpark_connect\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\nprint(session)\n\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import *\nfrom pyspark.sql.window import Window\n\nspark = snowpark_connect.server.init_spark_session()\n\nfrom snowflake.snowpark_connect.resources_initializer import wait_for_resource_initialization\nwait_for_resource_initialization()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8a3af77a-3887-444c-8577-13f58a37bf15",
   "metadata": {
    "language": "python",
    "name": "Transform_Raw_Channel"
   },
   "outputs": [],
   "source": "raw_channel = spark.read.table(\"MAYBANK_DEMO.BRONZE.RAW_CHANNEL\")\nraw_channel.show()\n\ndf_raw_channel = raw_channel.withColumn(\"CHANNEL_CODE_CLEAN\", upper(trim(col(\"CHANNEL_CODE\"))))\n    \n# 2. Deduplicate: Group by Clean Code, take first non-null attributes\ndf_raw_channel = df_raw_channel.groupBy(\"CHANNEL_CODE_CLEAN\").agg(\n    first(\"CHANNEL_NAME\").alias(\"CHANNEL_NAME\"),\n    first(\"CHANNEL_TYPE\").alias(\"CHANNEL_TYPE\"),\n    first(\"DEVICE_TYPE\").alias(\"DEVICE_TYPE\"),\n    first(\"LOCATION_TYPE\").alias(\"LOCATION_TYPE\"),\n    first(\"IS_24X7_FLAG\").alias(\"RAW_FLAG\")\n)\n\n# 3. Standardize Flag ('Yes'/'1' -> 'Y')\ndf_raw_channel = df_raw_channel.withColumn(\"IS_24X7_FLAG\", \n    when(upper(col(\"RAW_FLAG\")).isin(\"Y\", \"YES\", \"TRUE\", \"1\"), \"Y\").otherwise(\"N\")\n).drop(\"RAW_FLAG\").withColumnRenamed(\"CHANNEL_CODE_CLEAN\", \"CHANNEL_CODE\")\n\ndf_raw_channel.show()\n\ndf_raw_channel.write.mode(\"overwrite\").saveAsTable(\"MAYBANK_DEMO.SILVER.dim_channel\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c81b62d0-bc6d-4dc0-ac69-2ed67d0dc843",
   "metadata": {
    "language": "python",
    "name": "Transform_Raw_Behavior_Events"
   },
   "outputs": [],
   "source": "raw_behavior_event = spark.read.table(\"MAYBANK_DEMO.BRONZE.RAW_BEHAVIOR_EVENT\")\nraw_behavior_event.withColumn(\"CAMPAIGN_NAME\", trim(regexp_replace(col(\"CAMPAIGN_NAME\"), \"Â®\", \"\")))\n\nraw_behavior_event.show()\n\n# Cleaning 2: Normalize Device Type (Raw Agent String -> Category)\ndf_raw_behavior_event = raw_behavior_event.withColumn(\"DEVICE_TYPE\", \n    when(lower(col(\"DEVICE_TYPE\")).rlike(\"iphone|android|mobile\"), \"Mobile\")\n    .when(lower(col(\"DEVICE_TYPE\")).rlike(\"windows|mac|desktop\"), \"Desktop\")\n    .otherwise(col(\"DEVICE_TYPE\"))\n)\n\n# Cleaning 3: Title Case Traffic Source\ndf_raw_behavior_event = df_raw_behavior_event.withColumn(\"TRAFFIC_SOURCE\", initcap(col(\"TRAFFIC_SOURCE\")))\n\ndf_raw_behavior_event.select(\n    \"BEHAVIOR_EVENT_ID\", \"BEHAVIOR_EVENT_TYPE\", \"CHANNEL_CODE\", \n    \"CONTENT_ID\", \"CAMPAIGN_ID\", \"CAMPAIGN_NAME\", \n    \"DEVICE_TYPE\", \"TRAFFIC_SOURCE\", \"JOURNEY_STAGE\"\n)\ndf_raw_behavior_event.show()\n\ndf_raw_behavior_event.write.mode(\"overwrite\").saveAsTable(\"MAYBANK_DEMO.SILVER.dim_behavior_event\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bd1f8b0a-84c0-41da-b69e-0fbe9d7f875c",
   "metadata": {
    "language": "python",
    "name": "Transform_Raw_Behavior"
   },
   "outputs": [],
   "source": "raw_behavior = spark.read.table(\"MAYBANK_DEMO.BRONZE.RAW_BEHAVIOR\")\n\nraw_behavior.show()\n\ndf_raw_behavior = raw_behavior.select(\n        col(\"BEHAVIOR_RECORD_ID\"),\n        \n        # Cleaning 1: Handle Null Customer (Tag as Anonymous)\n        coalesce(col(\"CUSTOMER_ID\"), lit(\"ANONYMOUS\")).alias(\"CUSTOMER_ID\"),\n        \n        # Cleaning 2: Standardize Join Key (Fixes 'evt_page_casa' mismatch)\n        upper(trim(col(\"BEHAVIOR_EVENT_ID\"))).alias(\"BEHAVIOR_EVENT_ID\"),\n        \n        col(\"CHANNEL_CODE\"),\n        \n        # Cleaning 3: Parse Chaotic Timestamps -> Date\n        # Tries multiple patterns. If all fail, returns Null.\n        coalesce(\n            to_date(col(\"RAW_TIMESTAMP\"), \"yyyy-MM-dd'T'HH:mm:ssXXX\"), # ISO Offset\n            to_date(col(\"RAW_TIMESTAMP\"), \"yyyy-MM-dd'T'HH:mm:ss'Z'\"), # ISO UTC\n            to_date(col(\"RAW_TIMESTAMP\"), \"yyyy-MM-dd HH:mm:ss\")       # SQL Standard\n        ).alias(\"DATE_VALUE\"),\n        \n        col(\"SESSION_ID\"),\n        col(\"EVENT_SEQUENCE_IN_SESSION\"),\n        col(\"EVENT_VALUE\"),\n        col(\"IS_CONVERSION_FLAG\"),\n        col(\"CONVERSION_TYPE\"),\n        \n        # Cleaning 4: Cast Score to Float (Handles 'N/A', 'invalid', 'Error')\n        # Casting a non-numeric string to float results in Null in Spark\n        col(\"EXPERIENCE_SCORE\").cast(\"float\").alias(\"EXPERIENCE_SCORE\")\n    )\n    \n# Data Quality Filter: Drop rows where Date could not be parsed (Junk Data)\ndf_raw_behavior_clean = df_raw_behavior.filter(col(\"DATE_VALUE\").isNotNull())\n\ndf_raw_behavior_clean.show()\n\ndf_raw_behavior_clean.write.mode(\"overwrite\").saveAsTable(\"MAYBANK_DEMO.SILVER.fact_behavior\")",
   "execution_count": null
  }
 ]
}